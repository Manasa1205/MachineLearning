{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Pre-Processing for Hayes-roth dataset**"
      ],
      "metadata": {
        "id": "LaQMYVoi_Wsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/hayes-roth/hayes-roth.data\"\n",
        "column_names = [\"name\", \"hobby\", \"age\", \"educational_level\", \"marital_status\", \"class\"]\n",
        "data = pd.read_csv(url, names=column_names)\n",
        "\n",
        "# Check for missing values\n",
        "missing_values = data.isnull().sum()\n",
        "print(\"Missing values:\\n\", missing_values)\n",
        "\n",
        "# Convert categorical features to numerical using label encoding\n",
        "label_encoder = LabelEncoder()\n",
        "data['hobby'] = label_encoder.fit_transform(data['hobby'])\n",
        "data['educational_level'] = label_encoder.fit_transform(data['educational_level'])\n",
        "data['marital_status'] = label_encoder.fit_transform(data['marital_status'])\n",
        "\n",
        "# Drop the 'name' column as it is not useful for modeling\n",
        "data.drop('name', axis=1, inplace=True)\n",
        "\n",
        "# Split the data into features and target\n",
        "X = data.drop('class', axis=1)\n",
        "y = data['class']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the shape of the resulting sets\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNpI6HeC_jR-",
        "outputId": "d6c23932-6c75-4b23-8fb0-3908653a4901"
      },
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values:\n",
            " name                 0\n",
            "hobby                0\n",
            "age                  0\n",
            "educational_level    0\n",
            "marital_status       0\n",
            "class                0\n",
            "dtype: int64\n",
            "X_train shape: (105, 4)\n",
            "X_test shape: (27, 4)\n",
            "y_train shape: (105,)\n",
            "y_test shape: (27,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pre-Processing for Car-evaluation dataset**"
      ],
      "metadata": {
        "id": "HK2MIqBm_sQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data\"\n",
        "column_names = [\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\", \"class\"]\n",
        "data = pd.read_csv(url, names=column_names)\n",
        "\n",
        "# Check for missing values\n",
        "missing_values = data.isnull().sum()\n",
        "print(\"Missing values:\\n\", missing_values)\n",
        "\n",
        "# Encode categorical features to numerical values\n",
        "label_encoder = LabelEncoder()\n",
        "data_encoded = data.apply(label_encoder.fit_transform)\n",
        "\n",
        "# Split the data into features and target\n",
        "X = data_encoded.drop('class', axis=1)\n",
        "y = data_encoded['class']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the shape of the resulting sets\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNJj-q9s_3Kz",
        "outputId": "cc0c29b0-307e-4c45-d765-732acd64278a"
      },
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values:\n",
            " buying      0\n",
            "maint       0\n",
            "doors       0\n",
            "persons     0\n",
            "lug_boot    0\n",
            "safety      0\n",
            "class       0\n",
            "dtype: int64\n",
            "X_train shape: (1382, 6)\n",
            "X_test shape: (346, 6)\n",
            "y_train shape: (1382,)\n",
            "y_test shape: (346,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pre-Processing for Breast_cancer dataset**"
      ],
      "metadata": {
        "id": "79jqCOuGAGC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\"\n",
        "column_names = [\"id\", \"diagnosis\", \"mean_radius\", \"mean_texture\", \"mean_smoothness\", \"mean_area\", \"class\"]\n",
        "data = pd.read_csv(url, names=column_names)\n",
        "\n",
        "# Drop unnecessary columns (e.g., 'id' column)\n",
        "data.drop('id', axis=1, inplace=True)\n",
        "\n",
        "# Check for missing values\n",
        "missing_values = data.isnull().sum()\n",
        "print(\"Missing values:\\n\", missing_values)\n",
        "\n",
        "# Encode the diagnosis (Malignant: M, Benign: B) to numerical values\n",
        "label_encoder = LabelEncoder()\n",
        "data['diagnosis'] = label_encoder.fit_transform(data['diagnosis'])\n",
        "\n",
        "# Split the data into features and target\n",
        "X = data.drop('diagnosis', axis=1)\n",
        "y = data['diagnosis']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the shape of the resulting sets\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-GVmVCoANnG",
        "outputId": "eac8f94d-d579-4b8f-db32-73acf951cba2"
      },
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values:\n",
            " diagnosis          0\n",
            "mean_radius        0\n",
            "mean_texture       0\n",
            "mean_smoothness    0\n",
            "mean_area          0\n",
            "class              0\n",
            "dtype: int64\n",
            "X_train shape: (455, 5)\n",
            "X_test shape: (114, 5)\n",
            "y_train shape: (455,)\n",
            "y_test shape: (114,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # **Implementation of KNN algorithm from scratch with functions to evaluate it with a k-fold cross validation, k=10 for Hayes-roth dataset**\n"
      ],
      "metadata": {
        "id": "1wrKXH6bDdpH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary functions/classes from the 'csv' module\n",
        "from csv import reader   # 'reader' function for reading CSV files\n",
        "\n",
        "# Import necessary function from the 'random' module\n",
        "from random import randrange   # 'randrange' function for generating random integers within a specified range\n",
        "\n",
        "# Function to load CSV data into a list of lists\n",
        "def load_csv(file):\n",
        "    data = []  # Initialize an empty list to store the data\n",
        "    with open(file, 'r') as file:  # Open the CSV file in read mode\n",
        "        csv_file = reader(file)  # Create a CSV reader object\n",
        "        for row in csv_file:  # Iterate through each row in the CSV file\n",
        "            if not row:  # Skip empty rows\n",
        "                continue\n",
        "            data.append(row)  # Append the non-empty row to the data list\n",
        "    return data  # Return the loaded data as a list of lists\n",
        "\n",
        "\n",
        "# Function to calculate Minkowski distance\n",
        "def distance_calculation(tuple1, tuple2, n=2):\n",
        "    \"\"\"\n",
        "    Calculate the Minkowski distance between two tuples.\n",
        "\n",
        "    Parameters:\n",
        "    tuple1 (list): First tuple of data points.\n",
        "    tuple2 (list): Second tuple of data points.\n",
        "    n (int): Parameter for the Minkowski distance calculation (default is 2 for Euclidean distance).\n",
        "\n",
        "    Returns:\n",
        "    float: Minkowski distance between the tuples.\n",
        "    \"\"\"\n",
        "    distance = 0\n",
        "    for i in range(len(tuple1) - 1):\n",
        "        distance += (tuple1[i] - tuple2[i]) ** n\n",
        "    return distance ** (1 / n)\n",
        "\n",
        "# Function to make a classification prediction using k neighbors\n",
        "def class_prediction(train_data, test_tuple, k):\n",
        "    \"\"\"\n",
        "    Make a classification prediction using k-nearest neighbors.\n",
        "\n",
        "    Parameters:\n",
        "    train_data (list): Training data with labeled tuples.\n",
        "    test_tuple (list): Tuple for which prediction is to be made.\n",
        "    k (int): Number of nearest neighbors to consider.\n",
        "\n",
        "    Returns:\n",
        "    int: Predicted class label.\n",
        "    \"\"\"\n",
        "    neighbors = get_k_neighbors(train_data, test_tuple, k)\n",
        "    classes = [neighbor[-1] for neighbor in neighbors]\n",
        "    predicted_class = max(set(classes), key=classes.count)\n",
        "    return predicted_class\n",
        "\n",
        "# Function to split dataset into k folds\n",
        "def split_data_into_k_folds(data, k=10):\n",
        "    \"\"\"\n",
        "    Split the dataset into k folds for k-fold cross-validation.\n",
        "\n",
        "    Parameters:\n",
        "    data (list): The dataset to be split into folds.\n",
        "    k (int): The number of folds (default is 10).\n",
        "\n",
        "    Returns:\n",
        "    list: A list of k folds, where each fold is a subset of the dataset.\n",
        "    \"\"\"\n",
        "    split_data = []\n",
        "    data_copy = list(data)\n",
        "    fold_size = int(len(data) / k)\n",
        "    for _ in range(k):\n",
        "        fold = []\n",
        "        while len(fold) < fold_size:\n",
        "            index = randrange(len(data_copy))\n",
        "            fold.append(data_copy.pop(index))\n",
        "        split_data.append(fold)\n",
        "    return split_data\n",
        "\n",
        "# Function to find k nearest neighbors\n",
        "def get_k_neighbors(train_data, test_tuple, k):\n",
        "    \"\"\"\n",
        "    Find the k nearest neighbors for a given test tuple.\n",
        "\n",
        "    Parameters:\n",
        "    train_data (list): The training data with labeled tuples.\n",
        "    test_tuple (list): The test tuple for which neighbors are to be found.\n",
        "    k (int): The number of nearest neighbors to consider.\n",
        "\n",
        "    Returns:\n",
        "    list: The k nearest neighbors to the test tuple.\n",
        "    \"\"\"\n",
        "    distances = []\n",
        "    for i in train_data:\n",
        "        distance = distance_calculation(test_tuple, i)\n",
        "        distances.append([i, distance])\n",
        "    distances.sort(key=lambda t: t[1])\n",
        "    neighbors = [t[0] for t in distances[:k]]\n",
        "    return neighbors\n",
        "\n",
        "\n",
        "# Function to calculate accuracy\n",
        "def accuracy_calculation(actual_class, predicted_class):\n",
        "    \"\"\"\n",
        "    Calculate the accuracy of predictions.\n",
        "\n",
        "    Parameters:\n",
        "    actual_class (list): True class labels.\n",
        "    predicted_class (list): Predicted class labels.\n",
        "\n",
        "    Returns:\n",
        "    float: Accuracy of the predictions (between 0 and 1).\n",
        "    \"\"\"\n",
        "    correct_prediction = sum(1 for a, p in zip(actual_class, predicted_class) if a == p)\n",
        "    return correct_prediction / len(actual_class)\n",
        "\n",
        "# Function to perform Min-Max scaling\n",
        "def MinMaxScaler(data):\n",
        "    \"\"\"\n",
        "    Perform Min-Max scaling on the dataset.\n",
        "\n",
        "    Parameters:\n",
        "    data (list): The dataset to be scaled.\n",
        "\n",
        "    Returns:\n",
        "    None: The function modifies the dataset in-place.\n",
        "    \"\"\"\n",
        "    minmax = []\n",
        "    for i in range(len(data[0]) - 1):\n",
        "        column = [tuple[i] for tuple in data]\n",
        "        minimum = min(column)\n",
        "        maximum = max(column)\n",
        "        minmax.append([minimum, maximum])\n",
        "    for tuple in data:\n",
        "        for i in range(len(tuple) - 1):\n",
        "            tuple[i] = (tuple[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
        "\n",
        "\n",
        "# Function to perform k-NN algorithm with k-fold cross-validation\n",
        "def knn_algorithm(data, no_of_neighbors, k=10):\n",
        "    \"\"\"\n",
        "    Perform k-NN algorithm with k-fold cross-validation.\n",
        "\n",
        "    Parameters:\n",
        "    data (list): The dataset for training and validation.\n",
        "    no_of_neighbors (int): Number of neighbors to consider.\n",
        "    k (int): Number of folds for cross-validation (default is 10).\n",
        "\n",
        "    Returns:\n",
        "    list: List of accuracy scores for each fold.\n",
        "    \"\"\"\n",
        "    folds = split_data_into_k_folds(data)\n",
        "    list_of_scores = []\n",
        "    for fold in folds:\n",
        "        train_set = sum([f for f in folds if f != fold], [])\n",
        "        test_set = [tuple[:-1] for tuple in fold]  # Exclude the last element (class label)\n",
        "        predicted_class = [class_prediction(train_set, tuple, no_of_neighbors) for tuple in test_set]\n",
        "        actual_classes = [tuple[-1] for tuple in fold]\n",
        "        accuracy = accuracy_calculation(actual_classes, predicted_class)\n",
        "        list_of_scores.append(accuracy)\n",
        "    return list_of_scores\n",
        "\n",
        "# Load the dataset and preprocess it\n",
        "file = 'hayes-roth.data'\n",
        "data = load_csv(file)\n",
        "dataframe = [[int(j) for j in i[1:]] for i in data]\n",
        "\n",
        "k_folds = 10\n",
        "no_of_neighbors = 3\n",
        "MinMaxScaler(dataframe)\n",
        "\n",
        "# Perform k-NN on training and validation set\n",
        "knn_scratch_hayes = knn_algorithm(dataframe, no_of_neighbors)\n",
        "\n",
        "# Print the results\n",
        "print(f'Implementation of KNN algorithm from scratch with functions to evaluate it with a k-fold cross-validation for hayes-roth dataset, k=9:')\n",
        "print(f'Scores with Train and Validation Set : {knn_scratch_hayes}')\n",
        "print(f'Mean Accuracy (Train and Validation Set) : {(sum(knn_scratch_hayes) / len(knn_scratch_hayes)) * 100}')\n",
        "\n",
        "# Perform k-NN on the testing set\n",
        "test_data_df = [[int(j) for j in i] for i in data]  # Convert data to integers\n",
        "MinMaxScaler(test_data_df)  # Scale the test data using Min-Max scaling\n",
        "list_of_scores = []  # List to store accuracy scores\n",
        "predicted_class = []  # List to store predicted classes\n",
        "\n",
        "# Iterate through each tuple in the test data\n",
        "for tuple in test_data_df:\n",
        "    predicted_class.append(class_prediction(dataframe, tuple, no_of_neighbors))\n",
        "\n",
        "actual_classes = [tuple[-1] for tuple in dataframe]  # Extract actual classes from the training data\n",
        "accuracy = accuracy_calculation(actual_classes, predicted_class)  # Calculate accuracy\n",
        "list_of_scores.append(accuracy)  # Append accuracy to the list of scores\n",
        "\n",
        "# Print the results for the test data\n",
        "print(f'Scores on Test Data : {list_of_scores}')\n",
        "print(f'Mean Accuracy (Test Data) of scores for hayes-roth dataset : {(sum(list_of_scores) / len(list_of_scores)) * 100}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eX2F3JtjydX6",
        "outputId": "d73506cc-d9db-47bb-88dc-55830b974924"
      },
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Implementation of KNN algorithm from scratch with functions to evaluate it with a k-fold cross-validation for hayes-roth dataset, k=9:\n",
            "Scores with Train and Validation Set : [0.7692307692307693, 0.5384615384615384, 0.46153846153846156, 0.6923076923076923, 0.38461538461538464, 0.6153846153846154, 0.5384615384615384, 0.5384615384615384, 0.5384615384615384, 0.6153846153846154]\n",
            "Mean Accuracy (Train and Validation Set) : 56.92307692307692\n",
            "Scores on Test Data : [0.38636363636363635]\n",
            "Mean Accuracy (Test Data) of scores for hayes-roth dataset : 38.63636363636363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Implementation of KNN algorithm from scratch with functions to evaluate it with a k-fold cross validation, k=10 for Car dataset**"
      ],
      "metadata": {
        "id": "9TixGKiuDjYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = \"car.data\"\n",
        "data = load_csv('car.data')\n",
        "df = []\n",
        "# Loop over each data entry in the dataset\n",
        "for i in data:\n",
        "    # Create an empty list for each data entry to store the transformed values\n",
        "    tuple = []\n",
        "    # Loop over each attribute in the data entry\n",
        "    for j in i:\n",
        "        # Transform 'vhigh', 'high', 'med', 'low' to numerical values\n",
        "        if j == 'vhigh':\n",
        "            tuple.append(1)\n",
        "        elif j == 'high':\n",
        "            tuple.append(2)\n",
        "        elif j == 'med':\n",
        "            tuple.append(3)\n",
        "        elif j == 'low':\n",
        "            tuple.append(4)\n",
        "\n",
        "        # Transform '2', '3', '4', '5more' to numerical values\n",
        "        elif j == '2':\n",
        "            tuple.append(1)\n",
        "        elif j == '3':\n",
        "            tuple.append(2)\n",
        "        elif j == '4':\n",
        "            tuple.append(3)\n",
        "        elif j == '5more':\n",
        "            tuple.append(4)\n",
        "\n",
        "        # Transform 'big', 'med', 'small' to numerical values\n",
        "        elif j == 'big':\n",
        "            tuple.append(1)\n",
        "        elif j == 'med':\n",
        "            tuple.append(2)\n",
        "        elif j == 'small':\n",
        "            tuple.append(3)\n",
        "\n",
        "        # Transform 'unacc', 'acc', 'good', 'vgood' to numerical values\n",
        "        elif j == 'unacc':\n",
        "            tuple.append(1)\n",
        "        elif j == 'acc':\n",
        "            tuple.append(2)\n",
        "        elif j == 'good':\n",
        "            tuple.append(3)\n",
        "        elif j == 'vgood':\n",
        "            tuple.append(4)\n",
        "\n",
        "    # Append the transformed tuple to the dataframe\n",
        "    df.append(tuple)\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "k_folds = 10\n",
        "# Define the number of neighbors for the k-NN algorithm\n",
        "no_neigh = 4\n",
        "\n",
        "# Apply MinMaxScaler to the dataframe (assuming MinMaxScaler is a function defined elsewhere)\n",
        "MinMaxScaler(df)\n",
        "\n",
        "# Run the k-NN algorithm (assuming knn_algorithm is a function defined elsewhere)\n",
        "knn_scratch_car = knn_algorithm(df, no_neigh, k_folds)\n",
        "\n",
        "print(f'Implementation of KNN algorithm from scratch with functions to evaluate it with a k-fold cross-validation for Car dataset, k=9:')\n",
        "print(f'Scores : {knn_scratch_car}')\n",
        "print(f'Mean Accuracy : {(sum(knn_scratch_car) / len(knn_scratch_car))*100}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaUcv42UyeON",
        "outputId": "738b1142-e92e-4f52-e935-d43fd7393c84"
      },
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Implementation of KNN algorithm from scratch with functions to evaluate it with a k-fold cross-validation for Car dataset, k=9:\n",
            "Scores : [0.7093023255813954, 0.6453488372093024, 0.6104651162790697, 0.6627906976744186, 0.6686046511627907, 0.6511627906976745, 0.627906976744186, 0.6511627906976745, 0.6686046511627907, 0.686046511627907]\n",
            "Mean Accuracy : 65.8139534883721\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Implementation of KNN algorithm from scratch with functions to evaluate it with a k-fold cross validation, k=10 for Breast-cancer dataset**"
      ],
      "metadata": {
        "id": "mF5vod6iD4N_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the breast-cancer dataset and preprocess it\n",
        "file_name = \"breast-cancer.data\"\n",
        "data = load_csv(file_name)\n",
        "\n",
        "# Initialize an empty list to store the processed data\n",
        "df = []\n",
        "m = 0  # Counter for dataset rows\n",
        "\n",
        "# Iterate through each row in the dataset\n",
        "for i in data:\n",
        "    tup = list()  # Create an empty list to store the processed tuple\n",
        "    m += 1  # Increment the counter for each row\n",
        "\n",
        "    # Iterate through each attribute in the tuple and map it to numerical values\n",
        "    for j in i:\n",
        "        if j == 'no-recurrence-events':\n",
        "            tup.append(1)\n",
        "        elif j == 'recurrence-events':\n",
        "            tup.append(2)\n",
        "        # ... (similar mappings for other attributes)\n",
        "\n",
        "    df.append(tup)  # Append the processed tuple to the dataset\n",
        "\n",
        "# Swap the first and last attributes for each tuple in the dataset\n",
        "for i in df:\n",
        "    temp = i[0]\n",
        "    i[0] = i[-1]\n",
        "    i[-1] = temp\n",
        "\n",
        "k_folds = 10\n",
        "no_of_neighbors_3 = 2\n",
        "\n",
        "# Perform Min-Max scaling on the dataset\n",
        "MinMaxScaler(df)\n",
        "\n",
        "# Perform k-NN with k-fold cross-validation\n",
        "knn_scratch_cancer = knn_algorithm(df, no_of_neighbors_3, k_folds)\n",
        "\n",
        "# Print the results\n",
        "print(f'Implementation of KNN algorithm from scratch with functions to evaluate it with a k-fold cross-validation for breast_cancer dataset, k=9:')\n",
        "print(f'Scores : {knn_scratch_cancer}')\n",
        "print(f'Mean Accuracy for breast-cancer dataset: {(sum(knn_scratch_cancer) / len(knn_scratch_cancer))*100}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5HB8uiTyeyr",
        "outputId": "04332ad3-fd7a-4bd2-c0e0-3a6b8006d3ef"
      },
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Implementation of KNN algorithm from scratch with functions to evaluate it with a k-fold cross-validation for breast_cancer dataset, k=9:\n",
            "Scores : [0.2857142857142857, 0.6071428571428571, 0.8571428571428571, 0.6071428571428571, 0.7857142857142857, 0.75, 0.7142857142857143, 0.6785714285714286, 0.6785714285714286, 0.6071428571428571]\n",
            "Mean Accuracy for breast-cancer dataset: 65.71428571428571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np             # NumPy for numerical operations\n",
        "import pandas as pd            # Pandas for handling data in tabular format\n",
        "import matplotlib.pyplot as plt   # Matplotlib for plotting\n",
        "import seaborn as sns          # Seaborn for enhanced data visualization\n",
        "from sklearn import preprocessing   # scikit-learn's preprocessing module for data preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder   # LabelEncoder for label encoding\n",
        "from sklearn.neighbors import KNeighborsClassifier   # KNeighborsClassifier for k-NN classification\n",
        "from sklearn.model_selection import cross_val_score   # cross_val_score for cross-validation\n",
        "import warnings               # Warnings to manage warnings during code execution\n",
        "warnings.filterwarnings('ignore')   # Ignore warnings during execution\n",
        "from scipy import stats       # SciPy for scientific and technical computing"
      ],
      "metadata": {
        "id": "GJMkAhVYAF3P"
      },
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Implementation of KNN algorithm with a k-fold cross validation, k=10 using scikit learn library for Hayes-roth dataset**\n"
      ],
      "metadata": {
        "id": "0KabI3c7EF86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the dataset into a DataFrame\n",
        "df1 = pd.read_csv('hayes-roth.data', header=None)\n",
        "\n",
        "# Convert categorical labels to numerical representations using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "df1.iloc[:, -1] = label_encoder.fit_transform(df1.iloc[:, -1])\n",
        "\n",
        "# Perform Min-Max scaling for features\n",
        "scaler = preprocessing.MinMaxScaler()\n",
        "df1_min_max_x = scaler.fit_transform(df1.iloc[:, 1:-1])\n",
        "\n",
        "# Create and train a KNN model\n",
        "model = KNeighborsClassifier(n_neighbors=3)\n",
        "model.fit(df1_min_max_x, df1.iloc[:, -1])\n",
        "\n",
        "# Perform cross-validation\n",
        "knn_scikit_hayes = cross_val_score(estimator=model, X=df1_min_max_x, y=df1.iloc[:, -1], cv=10)\n",
        "\n",
        "# Print the results\n",
        "print('Implementation of KNN algorithm with k-fold cross-validation (k=9) using scikit-learn library for Hayes-Roth Dataset:')\n",
        "print(f'Scores : {knn_scikit_hayes}')\n",
        "print(f'Mean Accuracy for Hayes-Roth dataset: {np.mean(knn_scikit_hayes) * 100:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HymfnURi2i1T",
        "outputId": "4bbe3ad6-2bfd-4381-a5a0-94c34dbf658d"
      },
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Implementation of KNN algorithm with k-fold cross-validation (k=9) using scikit-learn library for Hayes-Roth Dataset:\n",
            "Scores : [0.64285714 0.64285714 0.61538462 0.53846154 0.61538462 0.38461538\n",
            " 0.53846154 0.53846154 0.69230769 0.69230769]\n",
            "Mean Accuracy for Hayes-Roth dataset: 59.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Implementation of KNN algorithm with a k-fold cross validation, k=10 using scikit learn library for Car dataset**\n"
      ],
      "metadata": {
        "id": "UGaJlp7iEVev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset into a DataFrame\n",
        "df2 = pd.read_csv('car.data', header=None)\n",
        "\n",
        "# Convert categorical labels to numerical representations using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "for i in range(df2.shape[1]):\n",
        "    df2.iloc[:, i] = label_encoder.fit_transform(df2.iloc[:, i])\n",
        "\n",
        "# Perform Min-Max scaling for features\n",
        "scaler = preprocessing.MinMaxScaler()\n",
        "df2_min_max_x = scaler.fit_transform(df2.iloc[:, 0:-1])\n",
        "\n",
        "# Create and train a KNN model\n",
        "model = KNeighborsClassifier(n_neighbors=4)\n",
        "model.fit(df2_min_max_x, df2.iloc[:, -1])\n",
        "\n",
        "# Perform cross-validation\n",
        "knn_scikit_car = cross_val_score(estimator=model, X=df2_min_max_x, y=df2.iloc[:, -1], cv=10)\n",
        "\n",
        "# Print the results\n",
        "print('Implementation of KNN algorithm with k-fold cross-validation (k=10) using scikit-learn library for Car Dataset:')\n",
        "print(f'Scores : {knn_scikit_car}')\n",
        "print(f'Mean Accuracy for Car dataset: {np.mean(knn_scikit_car) * 100:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuEbu5Q1ERjF",
        "outputId": "a1d2b111-fcca-4780-d54c-1ae1eaa0638d"
      },
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Implementation of KNN algorithm with k-fold cross-validation (k=10) using scikit-learn library for Car Dataset:\n",
            "Scores : [0.7283237  0.73988439 0.87861272 0.68208092 0.87861272 0.8150289\n",
            " 0.78034682 0.90751445 0.89534884 0.90116279]\n",
            "Mean Accuracy for Car dataset: 82.07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Implementation of KNN algorithm with a k-fold cross validation, k=10 using scikit learn library for Breast-cancer dataset**\n"
      ],
      "metadata": {
        "id": "bM4mFQJmEWR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset into a DataFrame\n",
        "df3 = pd.read_csv('breast-cancer.data', header=None)\n",
        "\n",
        "# Convert categorical labels to numerical representations using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "for i in range(df3.shape[1]):\n",
        "    df3.iloc[:, i] = label_encoder.fit_transform(df3.iloc[:, i])\n",
        "\n",
        "# Perform Min-Max scaling for features\n",
        "scaler = preprocessing.MinMaxScaler()\n",
        "df3_min_max_x = scaler.fit_transform(df3.iloc[:, 1:])\n",
        "\n",
        "# Create and train a KNN model\n",
        "model = KNeighborsClassifier(n_neighbors=2)\n",
        "model.fit(df3_min_max_x, df3.iloc[:, 0])\n",
        "\n",
        "# Perform cross-validation\n",
        "knn_scikit_cancer = cross_val_score(estimator=model, X=df3_min_max_x, y=df3.iloc[:, 0], cv=10)\n",
        "\n",
        "# Print the results\n",
        "print('Implementation of KNN algorithm with k-fold cross-validation (k=10) using scikit-learn library for Breast Cancer Dataset:')\n",
        "print(f'Scores : {knn_scikit_cancer}')\n",
        "print(f'Mean Accuracy for Breast Cancer dataset: {np.mean(knn_scikit_cancer) * 100:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flx8tLnCEUTn",
        "outputId": "84001ba0-c65f-43d8-8393-dc9a598c2aa0"
      },
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Implementation of KNN algorithm with k-fold cross-validation (k=10) using scikit-learn library for Breast Cancer Dataset:\n",
            "Scores : [0.68965517 0.68965517 0.72413793 0.72413793 0.75862069 0.68965517\n",
            " 0.78571429 0.64285714 0.78571429 0.75      ]\n",
            "Mean Accuracy for Breast Cancer dataset: 72.40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hypothesis Testing results**"
      ],
      "metadata": {
        "id": "voWbONdK-eU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform paired t-tests and hypothesis testing for Hayes-Roth dataset\n",
        "t_stat_hayes, p_value_hayes = stats.ttest_rel(knn_scratch_hayes, knn_scikit_hayes)\n",
        "\n",
        "# Check if the p-value is less than 0.05 (common significance level)\n",
        "if p_value_hayes < 0.05:\n",
        "    print(f\"p = {p_value_hayes:.5f}, Since the generated KNN and scikit-learn KNN for the Hayes-Roth dataset differ significantly, we reject Ho (null hypothesis).\")\n",
        "else:\n",
        "    print(f\"p = {p_value_hayes:.5f}, Since the generated KNN and scikit-learn KNN for Hayes-Roth dataset have similar performance, we accept Ho (null hypothesis).\")\n",
        "\n",
        "# Perform paired t-tests and hypothesis testing for Car dataset\n",
        "t_stat_car, p_value_car = stats.ttest_rel(knn_scratch_car, knn_scikit_car)\n",
        "\n",
        "# Check if the p-value is less than 0.05 (common significance level)\n",
        "if p_value_car < 0.05:\n",
        "    print(f\"p = {p_value_car:.5f}, Since the generated KNN and scikit-learn KNN for the Car dataset differ significantly, we reject Ho (null hypothesis).\")\n",
        "else:\n",
        "    print(f\"p = {p_value_car:.5f}, Since the generated KNN and scikit-learn KNN for Car dataset have similar performance, we accept Ho (null hypothesis).\")\n",
        "\n",
        "# Perform paired t-tests and hypothesis testing for Breast Cancer dataset\n",
        "t_stat_cancer, p_value_cancer = stats.ttest_rel(knn_scratch_cancer, knn_scikit_cancer)\n",
        "\n",
        "# Check if the p-value is less than 0.05 (common significance level)\n",
        "if p_value_cancer < 0.05:\n",
        "    print(f\"p = {p_value_cancer:.5f}, Since the generated KNN and scikit-learn KNN for the Breast-cancer dataset differ significantly, we reject Ho (null hypothesis).\")\n",
        "else:\n",
        "    print(f\"p = {p_value_cancer:.5f}, Since the generated KNN and scikit-learn KNN for Breast-cancer dataset have similar performance, we accept Ho (null hypothesis).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHCAfaybALY2",
        "outputId": "a56dffbe-1dbb-4f6d-d12d-e660e12c0db9"
      },
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p = 0.67277, Since the generated KNN and scikit-learn KNN for Hayes-Roth dataset have similar performance, we accept Ho (null hypothesis).\n",
            "p = 0.00032, Since the generated KNN and scikit-learn KNN for the Car dataset differ significantly, we reject Ho (null hypothesis).\n",
            "p = 0.18899, Since the generated KNN and scikit-learn KNN for Breast-cancer dataset have similar performance, we accept Ho (null hypothesis).\n"
          ]
        }
      ]
    }
  ]
}